{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Before you download data from CoRR, make sure that you have a NITRC account (https://www.nitrc.org) and that you are registered with the 1000 Functional Connectomes Project (https://www.nitrc.org/projects/fcon_1000/). \n",
    "\n",
    "2. This notebook should work regardless if you're downloading data on your local machine or on a server\n",
    "\n",
    "3. Run through the notebook. You will need to input your NITRC username, password and the directory you want to download the CoRR data into at the requested locations.\n",
    "\n",
    "4. The wget does not always work. It will work the first time you run it, but if you interrupt the kernel while it's running and try to do it again, it will fail to connect to the server. I am still trying to figure a way around this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "from lxml import html \n",
    "import pandas as pd\n",
    "from requests import Session\n",
    "import urllib3\n",
    "import urllib.request\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# constants\n",
    "# url for corr\n",
    "web_start = 'http://'\n",
    "nitrc_start = 'https://www.nitrc.org'\n",
    "url = 'fcon_1000.projects.nitrc.org/indi/CoRR/html/samples.html'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_links = [] # array that will hold links to the different datasets making up CoRR\n",
    "download_links = [] # array that will hold download links from all the datasets in data_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_name = '' #insert your user name for NITRC here\n",
    "password = '' #insert your passwork for NITRC here\n",
    "\n",
    "auth = {\"form_pw\": password, \"form_loginname\": user_name} # collect authentificatio information\n",
    "\n",
    "s = Session() # this session will hold cookies and remember login information\n",
    "\n",
    "# here we first login and get our session cookie\n",
    "s.post(\"https://www.nitrc.org/account/login.php\", auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract links of datasets from corr website\n",
    "r = requests.get(web_start + url)\n",
    "data = r.text\n",
    "soup = BeautifulSoup(data, 'lxml')\n",
    "\n",
    "# get the links to all the datasets\n",
    "for link in soup.find_all('a'):\n",
    "    if link.get('class') == ['reference', 'internal'] and link.get('href') not in ['qc.html', 'download.html', 'data_citation.html', '#datasets']:\n",
    "        data_links.append(link.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get internal url link to the datasets\n",
    "url_prefix = Path(url).parent.as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through each link if data_links and extract the links to their respective data downloads\n",
    "for link in data_links:\n",
    "    soup = BeautifulSoup((s.get(web_start + url_prefix+'/' + link)).text,\n",
    "    'lxml')\n",
    "    \n",
    "    # check the links of each dataset website\n",
    "    for l in soup.find_all('a'):\n",
    "        #get all the links that contain download files into the download_links array\n",
    "        if 'php' in l.get('href') and 'downloadlink' in l.get('href'):\n",
    "            \n",
    "            # hit the 'I agree' button on the NITRC website\n",
    "            temp_soup = BeautifulSoup(s.post(l.get('href') + '/?i_agree=1', auth).content, 'lxml')\n",
    "            \n",
    "            # get the download link from the redirected website\n",
    "            for d_link in temp_soup.find_all('a'):\n",
    "                if str('/frs/downloadlink') in str(d_link.get('href')):\n",
    "                    print('Adding:', link, '\\n', nitrc_start + d_link.get('href'))\n",
    "                    download_links.append(nitrc_start + d_link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_files = []\n",
    "# requests don't have adapters to ftp websites\n",
    "# but the http links in download_links redirect to an ftp server\n",
    "# that is why we catch the InvalidSchema error and extract the ftp links from the error message\n",
    "for download_file in download_links:\n",
    "    try:\n",
    "        s.get(download_file)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # Print Invalid Schema error and add it error_files\n",
    "        # There might be other errors that we're catching\n",
    "        print(\"Error: {}\".format(e))\n",
    "        error_files.append(\"{}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe with the error messages\n",
    "df_files = pd.DataFrame(error_files, columns=['Error_Message'])\n",
    "# extract the ftp link from error message\n",
    "df_files = df_files.assign(ftp_files = \n",
    "        [(x.split(\"No connection adapters were found for \")[1]) if 'Exceeded' not in str(x) else 'None' for x in error_files])\n",
    "# remove quotes from the ftp link\n",
    "df_files = df_files.assign(ftp_paths = \n",
    "        [x[1:len(x)-1] for x in df_files.ftp_files])\n",
    "# remove data from any error messages that aren't InvalidSchema\n",
    "df_files = df_files[df_files.ftp_paths != 'on']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display df and make sure that everything looks right\n",
    "df_files.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_directory = '' # insert directory where you want to store your CoRR files\n",
    "\n",
    "# go through each ftp file in the dataframe and download it\n",
    "for file in df_files.ftp_paths.values:\n",
    "    if file != 'on':\n",
    "        %cd {file_directory}\n",
    "        !wget -t inf -T 600 -c -v --passive-ftp --progress=bar -i {file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "66px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
